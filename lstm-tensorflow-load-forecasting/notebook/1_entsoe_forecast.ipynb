{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Category Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the features: ['all', 'actual', 'entsoe', 'weather_t', 'weather_i', 'holiday', 'weekday', 'hour', 'month']\n",
    "model_cat_id = \"01\"\n",
    "feature = ['actual', 'entsoe']\n",
    "\n",
    "# LSTM layer configuration\n",
    "layer_conf = [ True, True, True]\n",
    "cells = [[ 5, 10, 20, 30, 50, 75, 100, 125, 150], [0, 10, 20, 50], [0, 10, 15, 20]]\n",
    "dropout = [0, 0.1, 0.2]\n",
    "batch_size = [8]\n",
    "timesteps = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select backend & Check if keras work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import itertools\n",
    "import datetime as dt\n",
    "from decimal import *\n",
    "import pytz\n",
    "import time as t\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from numpy import newaxis\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as stattools\n",
    "from tabulate import tabulate\n",
    "import math\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (9, 5)\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from lstm_load import data, lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.path.dirname(''), '../data/fulldataset.csv')\n",
    "loc_tz = pytz.timezone('Europe/Zurich')\n",
    "split_date = loc_tz.localize(dt.datetime(2017,2,1,0,0,0,0))\n",
    "validation_split = 0.2\n",
    "epochs = 30\n",
    "verbose = 0\n",
    "results = pd.DataFrame(columns=['module_name', 'config', 'dropout', 'train_loss', 'train_rmse', 'train_mae', 'train_mape', 'valid_loss', 'valid_rmse', 'valid_mae', 'valid_mape', 'test_rmse', 'test_mae', 'test_mape', 'epochs', 'batch_train', 'input_shape', 'total_time', 'time_step', 'splits'])\n",
    "early_stopping = True\n",
    "min_delta = 0.006\n",
    "patience = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(model_name=None, layer_conf=None, cells=None, dropout=None, batch_size=None, timesteps=None):\n",
    "    models = []\n",
    "    layer_conb = list(itertools.product(*cells))\n",
    "    configs = [layer_conb, dropout, batch_size, timesteps]\n",
    "    combinations = list(itertools.product(*configs))\n",
    "\n",
    "    for ix, comb in enumerate(combinations):\n",
    "        m_name = model_name\n",
    "        m_name += str(ix + 1)\n",
    "\n",
    "        layers = []\n",
    "        for idx, level in enumerate(comb[0]):\n",
    "            return_sequence = True\n",
    "            if all(size == 0 for size in comb[0][idx + 1:]) == True:\n",
    "                return_sequence = False\n",
    "            if (idx + 1) == len(comb[0]):\n",
    "                return_sequence = False\n",
    "            if level > 0:\n",
    "                layers.append({'type': 'lstm', 'cells': level, 'dropout': comb[1], 'statful': layer_conf[idx], 'ret_seq': return_sequence })\n",
    "                m_name += '_1-' + str(comb[1])\n",
    "        if comb[1] > 0:\n",
    "            m_name += '_d-' + str(comb[1])\n",
    "        model_config = {\n",
    "            'name': m_name,\n",
    "            'layers': layers,\n",
    "            'batch_size': comb[2],\n",
    "            'timesteps': comb[3]\n",
    "        }\n",
    "        models.append(model_config)\n",
    "\n",
    "        print('==================')\n",
    "        print(tabulate([\n",
    "            ['Number of model configs generated', len(combinations)]],\n",
    "            tablefmt=\"jira\", numalign=\"right\", floatfmt=\".3f\"))\n",
    "        return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "| Number of model configs generated | 432 |\n"
     ]
    }
   ],
   "source": [
    "result_dir = '../results/notebook_' + model_cat_id + '/'\n",
    "plot_dir = '../plots/notebook_' + model_cat_id + '/'\n",
    "model_dir = '../models/notebook_' + model_cat_id + '/'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "output_table = result_dir + model_cat_id + '_results_' + t.strftime(\"%Y%m%d\") + '.csv'\n",
    "test_output_table = result_dir + model_cat_id + '_test_results' + t.strftime(\"%Y%m%d\") + '.csv'\n",
    "\n",
    "models = []\n",
    "models = generate_combinations(\n",
    "    model_name=model_cat_id + '_', layer_conf=layer_conf, cells=cells, dropout=dropout,\n",
    "    batch_size=batch_size,timesteps=[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Already tz-aware, use tz_convert to convert.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Denmark\\work\\project\\DS\\Forecast_power-trading\\lstm-tensorflow-load-forecasting\\lstm_load\\data.py:23\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, update_date, modules)\u001b[0m\n\u001b[0;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m], index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     22\u001b[0m df[\u001b[38;5;28mlist\u001b[39m(indicator_vars\u001b[38;5;241m.\u001b[39mkeys())] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;28mlist\u001b[39m(indicator_vars\u001b[38;5;241m.\u001b[39mkeys())]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtz_localize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update_date:\n",
      "File \u001b[1;32mc:\\Users\\86176\\tf\\Lib\\site-packages\\pandas\\core\\generic.py:11725\u001b[0m, in \u001b[0;36mNDFrame.tz_localize\u001b[1;34m(self, tz, axis, level, copy, ambiguous, nonexistent)\u001b[0m\n\u001b[0;32m  11723\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, ax\u001b[38;5;241m.\u001b[39mname):\n\u001b[0;32m  11724\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe level \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not valid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m> 11725\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[43m_tz_localize\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonexistent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11727\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write())\n\u001b[0;32m  11728\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mset_axis(ax, axis\u001b[38;5;241m=\u001b[39maxis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\86176\\tf\\Lib\\site-packages\\pandas\\core\\generic.py:11713\u001b[0m, in \u001b[0;36mNDFrame.tz_localize.<locals>._tz_localize\u001b[1;34m(ax, tz, ambiguous, nonexistent)\u001b[0m\n\u001b[0;32m  11711\u001b[0m     ax \u001b[38;5;241m=\u001b[39m DatetimeIndex([], tz\u001b[38;5;241m=\u001b[39mtz)\n\u001b[0;32m  11712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11713\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtz_localize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonexistent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnonexistent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ax\n",
      "File \u001b[1;32mc:\\Users\\86176\\tf\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:293\u001b[0m, in \u001b[0;36mDatetimeIndex.tz_localize\u001b[1;34m(self, tz, ambiguous, nonexistent)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;129m@doc\u001b[39m(DatetimeArray\u001b[38;5;241m.\u001b[39mtz_localize)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtz_localize\u001b[39m(\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m     nonexistent: TimeNonexistent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    292\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m--> 293\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtz_localize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnonexistent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(arr, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\86176\\tf\\Lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:81\u001b[0m, in \u001b[0;36mravel_compat.<locals>.method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(meth)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmethod\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndarray\u001b[38;5;241m.\u001b[39mflags\n\u001b[0;32m     84\u001b[0m     flat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mravel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\86176\\tf\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:1083\u001b[0m, in \u001b[0;36mDatetimeArray.tz_localize\u001b[1;34m(self, tz, ambiguous, nonexistent)\u001b[0m\n\u001b[0;32m   1081\u001b[0m         new_dates \u001b[38;5;241m=\u001b[39m tz_convert_from_utc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masi8, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz, reso\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_creso)\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1083\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlready tz-aware, use tz_convert to convert.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1085\u001b[0m     tz \u001b[38;5;241m=\u001b[39m timezones\u001b[38;5;241m.\u001b[39mmaybe_get_tz(tz)\n",
      "\u001b[1;31mTypeError\u001b[0m: Already tz-aware, use tz_convert to convert."
     ]
    }
   ],
   "source": [
    "df = data.load_dataset(path=abspath, modules=feature)\n",
    "df_scaled = df.copy()\n",
    "df_scaled = df_scaled.dropna()\n",
    "floats = [key for key in dict(df_scaled.dtypes) if dict(df_scaled.dtypes)[key] in ['float64']]\n",
    "scaler =  StandardScaler()\n",
    "scaled_columns = scaler.fit_transform(df_scaled[floats]) # noraml distribution\n",
    "df_scaled[floats] = scaled_columns\n",
    "df_train = df_scaled.loc[(df_scaled.index < split_date)].copy()\n",
    "df_test = df_scaled.loc[df_scaled.index >= split_date].copy()\n",
    "y_train = df_train['actual'].copy()\n",
    "X_train = df_train.drop('actual', axis=1).copy()\n",
    "y_test = df_test['actual'].copy()\n",
    "X_test = df_test.drop('actual', axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training models on all configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
