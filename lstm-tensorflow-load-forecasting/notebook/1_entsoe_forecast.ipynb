{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Category Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the features: ['all', 'actual', 'entsoe', 'weather_t', 'weather_i', 'holiday', 'weekday', 'hour', 'month']\n",
    "model_cat_id = \"01\"\n",
    "feature = ['actual', 'entsoe']\n",
    "\n",
    "# LSTM layer configuration\n",
    "layer_conf = [ True, True, True]\n",
    "cells = [[ 5, 10, 20, 30, 50, 75, 100, 125, 150], [0, 10, 20, 50], [0, 10, 15, 20]]\n",
    "dropout = [0, 0.1, 0.2]\n",
    "batch_size = [8]\n",
    "timesteps = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select backend & Check if keras work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import itertools\n",
    "import datetime as dt\n",
    "from decimal import *\n",
    "import pytz\n",
    "import time as t\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from numpy import newaxis\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as stattools\n",
    "from tabulate import tabulate\n",
    "import math\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (9, 5)\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from lstm_load import data, lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rmse: Root Mean Square Error - 模型预测值与实际值之间的差异\n",
    "mae: Mean Absolute Error - 衡量预测值与实际值的差异。\n",
    "mape: Mean Absolute Percentage Error - 衡量预测误差相对于实际值的百分比\n",
    "train_loss - 存储训练集上的损失值。损失函数是用于衡量模型预测误差的标准。\n",
    "valid_loss - 存储验证集上的损失值。用于评估模型在未见数据上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ntpath' has no attribute 'abs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/fulldataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m loc_tz \u001b[38;5;241m=\u001b[39m pytz\u001b[38;5;241m.\u001b[39mtimezone(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEurope/Zurich\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m split_date \u001b[38;5;241m=\u001b[39m loc_tz\u001b[38;5;241m.\u001b[39mlocalize(dt\u001b[38;5;241m.\u001b[39mdatetime(\u001b[38;5;241m2017\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'ntpath' has no attribute 'abs'"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.path.abs(''), '../data/fulldataset.csv')\n",
    "loc_tz = pytz.timezone('Europe/Zurich')\n",
    "split_date = loc_tz.localize(dt.datetime(2017,2,1,0,0,0,0))\n",
    "validation_split = 0.2\n",
    "epochs = 30\n",
    "verbose = 0\n",
    "results = pd.DataFrame(columns=['module_name', 'config', 'dropout', 'train_loss', 'train_rmse', 'train_mae', 'train_mape', 'valid_loss', 'valid_rmse', 'valid_mae', 'valid_mape', 'test_rmse', 'test_mae', 'test_mape', 'epochs', 'batch_train', 'input_shape', 'total_time', 'time_step', 'splits'])\n",
    "early_stopping = True\n",
    "min_delta = 0.006\n",
    "patience = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(model_name=None, layer_conf=None, cells=None, dropout=None, batch_size=None, timesteps=None):\n",
    "    models = []\n",
    "    layer_conb = list(itertools.product(*cells))\n",
    "    configs = [layer_conb, dropout, batch_size, timesteps]\n",
    "    combinations = list(itertools.product(*configs))\n",
    "\n",
    "    for ix, comb in enumerate(combinations):\n",
    "        m_name = model_name\n",
    "        m_name += str(ix + 1)\n",
    "\n",
    "        layers = []\n",
    "        for idx, level in enumerate(comb[0]):\n",
    "            return_sequence = True\n",
    "            if all(size == 0 for size in comb[0][idx + 1:]) == True:\n",
    "                return_sequence = False\n",
    "            if (idx + 1) == len(comb[0]):\n",
    "                return_sequence = False\n",
    "            if level > 0:\n",
    "                layers.append({'type': 'lstm', 'cell': level, 'dropout': comb[1], 'statful': layer_conf[idx], 'ret_seq': return_sequence })\n",
    "                m_name += '_1-' + str(comb[1])\n",
    "        if comb[1] > 0:\n",
    "            m_name += '_d-' + str(comb[1])\n",
    "        model_config = {\n",
    "            'name': m_name,\n",
    "            'layers': layers,\n",
    "            'batch_size': comb[2],\n",
    "            'timesteps': comb[3]\n",
    "        }\n",
    "        models.append(model_config)\n",
    "\n",
    "        print('==================')\n",
    "        print(tabulate([\n",
    "            ['Number of model configs generated', len(combinations)]],\n",
    "            tablefmt=\"jira\", numalign=\"right\", floatfmt=\".3f\"))\n",
    "        return models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
