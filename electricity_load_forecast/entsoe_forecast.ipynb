{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters selection\n",
    "\n",
    "- Model category\n",
    "- Features\n",
    "- Layers\n",
    "- Cells\n",
    "- Regularization\n",
    "- Batch size\n",
    "- Timesteps\n",
    "\n",
    "### Neural Network Layers and Neuron Counts\n",
    "\n",
    "| Layer 1 (Input Layer)     | Layer 2 (Hidden Layer) | Layer 3 (Hidden Layer) |\n",
    "|---------------------------|------------------------|------------------------|\n",
    "| 5                         | 0                      | 0                      |\n",
    "| 10                        | 10                     | 10                     |\n",
    "| 20                        | 20                     | 15                     |\n",
    "| 30                        | 50                     | 20                     |\n",
    "| 50                        |                        |                        |\n",
    "| 75                        |                        |                        |\n",
    "| 100                       |                        |                        |\n",
    "| 125                       |                        |                        |\n",
    "| 150                       |                        |                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model category name used throughout the subsequent analysis\n",
    "model_catg_id = \"01\"\n",
    "\n",
    "# Load features from dataset:\n",
    "# ['all', 'actual', 'entsoe', 'weather_t', 'weather_i', 'holiday', 'weekday', 'hour', 'month']\n",
    "features = ['actual', 'entsoe']\n",
    "\n",
    "# LSTM Layer configuration\n",
    "# ========================\n",
    "# Stateful True or false\n",
    "layer_conf = [True, True, True]\n",
    "# Number of neurons per layer\n",
    "cells = [[ 5, 10, 20, 30, 50, 75, 100, 125, 150 ], [0, 10, 20, 50], [0, 10, 15, 20]]\n",
    "# Regularization per layer\n",
    "dropout = [0, 0.1, 0.2]\n",
    "# Size of how many samples are used for one forward/backward pass\n",
    "batch_size = [8]\n",
    "# In a sense this is the output neuron dimension, or how many timesteps the neuron should output. Currently not implemented, defaults to 1.\n",
    "timesteps = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages update its usage:  [statsmodels](https://www.statsmodels.org/stable/tsa.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import itertools\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import time as t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "# from pandas import datetime\n",
    "from numpy import newaxis\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "# from statsmodels.tsa import stattools\n",
    "import statsmodels.api as stattools\n",
    "from tabulate import tabulate\n",
    "import math\n",
    "\n",
    "import keras as keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, LSTM\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# %matplotlib - max figure size\n",
    "mpl.rcParams['figure.figsize'] = (9.0,5.0)\n",
    "\n",
    "# Import custom module functions\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from lstm_load_forecasting import data, lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.path.abspath(''), '../data/fulldataset.csv')\n",
    "\n",
    "# Split date for train and test data. \n",
    "# As the TBATS and ARIMA benchmark needs 2 full cycle of all seasonality, needs to be after jan 01. \n",
    "loc_tz = pytz.timezone('Europe/Zurich')\n",
    "split_date = loc_tz.localize(dt.datetime(2017,2,1,0,0,0,0))\n",
    "\n",
    "# Validation split percentage\n",
    "validation_split = 0.2\n",
    "# How many epochs in total\n",
    "epochs = 30\n",
    "# Set verbosity level. 0 for only per model, 1 for progress bar...\n",
    "verbose = 0\n",
    "\n",
    "# Dataframe containing the relevant data from training of all models\n",
    "results = pd.DataFrame(columns=['model_name', 'config', 'dropout',\n",
    "                                'train_loss', 'train_rmse', 'train_mae', 'train_mape', \n",
    "                                'valid_loss', 'valid_rmse', 'valid_mae', 'valid_mape', \n",
    "                                'test_rmse', 'test_mae', 'test_mape',\n",
    "                                'epochs', 'batch_train', 'input_shape',\n",
    "                                'total_time', 'time_step', 'splits'\n",
    "                               ])\n",
    "# Early stopping parameters\n",
    "early_stopping = True\n",
    "min_delta = 0.006\n",
    "patience = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output path\n",
    "res_dir = '../results/notebook_' + model_catg_id + '/'\n",
    "plot_dir = '../plots/notebook_' + model_catg_id + '/'\n",
    "model_dir = '../models/notebook_' + model_catg_id + '/'\n",
    "os.makedirs(res_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
